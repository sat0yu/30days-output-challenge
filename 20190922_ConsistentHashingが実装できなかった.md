同僚の発案で制限時間30分の中で3台構成の分散KVSを実装することになった。
筆者は制限時間内はおろか、2時間以上経っても同期の仕組みが実装できずにいたが、発案者はコンシステントハッシングを用いて分散KVSの実装をしていた。

筆者がコンシステントハッシングという単語をはじめて聞いたのは、一年ほど前にまさに上述の同僚からだった。
コンシステントハッシング自体は分散システムに限られた手法ではない。ある特定の条件を満たすハッシュ関数をコンシステントハッシュと呼ぶのだが、そういえば以前同僚から本手法の話を聞いた際も、今回同様に分散データストアを例にして説明してくれていた。

分散データストアは、その名が示すとおり、データを複数のノードに分散配置することで負荷分散を図る。
その際に問題となるのが、あるノードに問題がおきて動作を停止した際の復旧動作だ。
分散データストアにおいて、あるノードにしか存在しないデータがあると、分散データストア全体の可用性は各ノードの可用性でキャップされてしまう。
そのため、分散データストアでは同じデータを複数のノードに分散配置することで耐障害性を高める。

しかし、データを分散配置するにも別の問題がでてくる。
すなわち、各ノードが担当するデータの範囲を適切に設定する必要が生まれてくる。
すべてのノードにすべてのデータを分散配置したのでは、十分なスケールメリットを得られない。
一方でデータ範囲の重複を少なくしすぎると、上記の議論のとおり可用性が下がってしまう。
さらに、データ範囲の定義はノードの追加・削除操作にも大きく影響を及ぼす。
新たにノードを追加(削除)した場合に、データ範囲の調節によって再配置（移動）されるデータは少ないほうが望ましい。

この問題に対する有効な手段がコンシステントハッシングだ。
実際に有名な分散データストアApache Cassandraはコンシステントハッシングを採用している。
コンシステントハッシングでは、Kをキーの数、nをノード数とすると、平均K/n個のデータの再配置で済む。
コンシステントハッシング自体の説明はすでに豊富に存在しているため本文では省略する。

一般に、知識として持っていることでも、冒頭の筆者の例のように、実際に手を動かす・実装するとなるとうまくいかないことはよくある。
インターネットによってあらゆる情報を簡単に手に入れられる時代になったからこそ、実際に行動に移せるかどうかが一流とそれ以外と分けるわずかな差になるのかもしれない。
